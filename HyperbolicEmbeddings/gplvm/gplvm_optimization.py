from __future__ import annotations

import time
import warnings
from typing import Any, Callable, Dict, List, NamedTuple, Optional, Set, Tuple, Union
from collections import OrderedDict
from abc import ABC, abstractmethod
from inspect import signature
import logging

import math
import numpy as np
import torch
from torch import Tensor
from torch.nn import Module
from torch.optim.adam import Adam
from torch.optim.optimizer import Optimizer
from torch.optim.lr_scheduler import ReduceLROnPlateau
from gpytorch import settings as gpt_settings
from gpytorch.mlls.marginal_log_likelihood import MarginalLogLikelihood
from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood
from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood
from gpytorch.utils.errors import NanError, NotPSDError
from scipy.optimize import Bounds, minimize

from geoopt.optim import RiemannianAdam, RiemannianSGD

from HyperbolicEmbeddings.utils.numpy_gpytorch_converter import module_to_array, set_params_with_array, TorchAttr
from HyperbolicEmbeddings.hyperbolic_manifold.math_ops_hyperbolic import clamp


"""
All the functions and classes of this file have been copied or adapted from functions and classes of botorch.optim.fit
"""

ParameterBounds = Dict[str, Tuple[Optional[float], Optional[float]]]
TScipyObjective = Callable[
    [np.ndarray, MarginalLogLikelihood, Dict[str, TorchAttr]], Tuple[float, np.ndarray]
]
TModToArray = Callable[
    [Module, Optional[ParameterBounds], Optional[Set[str]]],
    Tuple[np.ndarray, Dict[str, TorchAttr], Optional[np.ndarray]],
]
TArrayToMod = Callable[[Module, np.ndarray, Dict[str, TorchAttr]], Module]


class OptimizationIteration(NamedTuple):
    itr: int
    fun: float
    time: float


def _scipy_objective_and_grad(
    x: np.ndarray, mll: MarginalLogLikelihood, property_dict: Dict[str, TorchAttr]
) -> Tuple[float, np.ndarray]:
    r"""Get objective and gradient in format that scipy expects.

    This function was adapted from the function botorch.optim.utils._scipy_objective_and_grad of botorch to optimize
    Bayesian GPLVMs instead of gpytorch GP models.

    Args:
        x: The (flattened) input parameters.
        mll: The MarginalLogLikelihood module to evaluate.
        property_dict: The property dictionary required to "unflatten" the input
            parameter vector, as generated by `module_to_array`.

    Returns:
        2-element tuple containing

        - The objective value.
        - The gradient of the objective.
    """
    mll = set_params_with_array(mll, x, property_dict)
    if hasattr(mll.model.train_inputs, '__call__'):
        # For variational GPLVMs, the training inputs are sampled at each iteration
        # For back-constrained GPLVMs, the training inputs are computed as a function of the training targets
        train_inputs = mll.model.train_inputs()
    else:
        # For exact GPLVMs, the training inputs are fixed
        train_inputs = mll.model.train_inputs[0]

    train_targets = mll.model.train_targets
    mll.zero_grad()
    try:  # catch linear algebra errors in gpytorch
        output = mll.model(train_inputs)
        args = [output, train_targets] + _get_extra_mll_args(mll)
        loss = -mll(*args).sum()
    except RuntimeError as e:
        return _handle_numerical_errors(error=e, x=x)
    loss.backward()
    param_dict = OrderedDict(mll.named_parameters())
    grad = []
    for p_name in property_dict:
        t = param_dict[p_name].grad
        if t is None:
            # this deals with parameters that do not affect the loss
            grad.append(np.zeros(property_dict[p_name].shape.numel()))
        else:
            grad.append(t.detach().view(-1).cpu().double().clone().numpy())
    mll.zero_grad()
    return loss.item(), np.concatenate(grad)


def _get_extra_mll_args(
    mll: MarginalLogLikelihood,
) -> Union[List[Tensor], List[List[Tensor]]]:
    r"""Obtain extra arguments for MarginalLogLikelihood objects.
    This function was duplicated from botorch.optim.utils.

    Get extra arguments (beyond the model output and training targets) required
    for the particular type of MarginalLogLikelihood for a forward pass.

    Args:
        mll: The MarginalLogLikelihood module.

    Returns:
        Extra arguments for the MarginalLogLikelihood.
        Returns an empty list if the mll type is unknown.
    """
    if isinstance(mll, ExactMarginalLogLikelihood):
        if hasattr(mll.model.train_inputs, '__call__'):
            return [mll.model.train_inputs()]
        else:
            return list(mll.model.train_inputs)
    elif isinstance(mll, SumMarginalLogLikelihood):
        return [list(x) for x in mll.model.train_inputs]
    return []


def get_transformed_parameters(mll: MarginalLogLikelihood) -> dict[str, np.ndarray]:
    parameters = {}
    for raw_name, raw_param in mll.named_parameters():
        constraint = mll.constraint_for_parameter_name(raw_name)
        param = constraint.transform(raw_param) if constraint else raw_param
        name = raw_name.replace('raw_', '')
        parameters[name] = param.cpu().detach().squeeze().numpy()
    return parameters


def _handle_numerical_errors(
    error: RuntimeError, x: np.ndarray
) -> Tuple[float, np.ndarray]:
    if isinstance(error, NotPSDError):
        raise error
    error_message = error.args[0] if len(error.args) > 0 else ""
    if (
        isinstance(error, NanError)
        or "singular" in error_message  # old pytorch message
        or "input is not positive-definite" in error_message  # since pytorch #63864
    ):
        return float("nan"), np.full_like(x, "nan")
    raise error  # pragma: nocover


def _filter_kwargs(function: Callable, **kwargs: Any) -> Any:
    r"""Filter out kwargs that are not applicable for a given function.
    Return a copy of given kwargs dict with only the required kwargs.
    This function was duplicated from botorch.optim.utils."""
    return {k: v for k, v in kwargs.items() if k in signature(function).parameters}


class StoppingCriterion(ABC):
    r"""Base class for evaluating optimization convergence.
    This class was duplicated from botorch.optim.stopping.

    Stopping criteria are implemented as a objects rather than a function, so that they
    can keep track of past function values between optimization steps.
    """

    @abstractmethod
    def evaluate(self, fvals: Tensor) -> bool:
        r"""Evaluate the stopping criterion.

        Args:
            fvals: tensor containing function values for the current iteration. If
                `fvals` contains more than one element, then the stopping criterion is
                evaluated element-wise and True is returned if the stopping criterion is
                true for all elements.

        Returns:
            Stopping indicator (if True, stop the optimziation).
        """
        pass  # pragma: no cover


class VanillaStoppingCriterion(StoppingCriterion):
    r"""
    Stopping criterion that raises the boolean flag after a defined number of training iterations have passed. This
    should resemble the vanilla implementation of a stopping criterion for any optimization algorithm. Performs an
    internal computation of the number of times this function has been called, and raises the stop flag if this
    number exceeds the parameter 'maxiter' that is passed when calling fit_gplvm_torch.

    """
    def __init__(self, maxiter: int = 10000) -> None:
        r"""
        Initialising the vanilla stopping criterion

        Parameters
        ----------
        maxiter : Optional[int]
            maximum number of iterations. (default: 10000)

        """
        self.maxiter = maxiter
        self.iter = 0

    def evaluate(self) -> bool:
        r"""
        Evaluate the stopping criterion.

        Returns
        -------
        bool
            stopping indicator that stops the optimization if true

        Note
        ----
        (1) Since this vanilla implementation does not require the loss for computation, no parameter needs to be
            passed into its signature when the evaluate method is called

        """

        # Stop the optimization if the maximum number of iterations is reached
        self.iter += 1
        if self.iter == self.maxiter:
            return True

        return False
    

class ExpMAStoppingCriterion(StoppingCriterion):
    r"""Exponential moving average stopping criterion.
    This class was duplicated from botorch.optim.stopping.

    Computes an exponentially weighted moving average over window length `n_window`
    and checks whether the relative decrease in this moving average between steps
    is less than a provided tolerance level. That is, in iteration `i`, it computes

        v[i,j] := fvals[i - n_window + j] * w[j]

    for all `j = 0, ..., n_window`, where `w[j] = exp(-eta * (1 - j / n_window))`.
    Letting `ma[i] := sum_j(v[i,j])`, the criterion evaluates to `True` whenever

        (ma[i-1] - ma[i]) / abs(ma[i-1]) < rel_tol (if minimize=True)
        (ma[i] - ma[i-1]) / abs(ma[i-1]) < rel_tol (if minimize=False)
    """

    def __init__(
        self,
        maxiter: int = 10000,
        minimize: bool = True,
        n_window: int = 10,
        eta: float = 1.0,
        rel_tol: float = 1e-5,
    ) -> None:
        r"""Exponential moving average stopping criterion.

        Args:
            maxiter: Maximum number of iterations.
            minimize: If True, assume minimization.
            n_window: The size of the exponential moving average window.
            eta: The exponential decay factor in the weights.
            rel_tol: Relative tolerance for termination.
        """
        self.maxiter = maxiter
        self.minimize = minimize
        self.n_window = n_window
        self.rel_tol = rel_tol
        self.iter = 0
        weights = torch.exp(torch.linspace(-eta, 0, self.n_window))
        self.weights = weights / weights.sum()
        self._prev_fvals = None

    def evaluate(self, fvals: Tensor) -> bool:
        r"""Evaluate the stopping criterion.

        Args:
            fvals: tensor containing function values for the current iteration. If
                `fvals` contains more than one element, then the stopping criterion is
                evaluated element-wise and True is returned if the stopping criterion is
                true for all elements.

        Returns:
            Stopping indicator (if True, stop the optimziation).
        """
        self.iter += 1
        if self.iter == self.maxiter:
            return True

        if self._prev_fvals is None:
            self._prev_fvals = fvals.unsqueeze(0)
        else:
            self._prev_fvals = torch.cat(
                [self._prev_fvals[-self.n_window :], fvals.unsqueeze(0)]
            )

        if self._prev_fvals.size(0) < self.n_window + 1:
            return False

        weights = self.weights
        weights = weights.to(fvals)
        if self._prev_fvals.ndim > 1:
            weights = weights.unsqueeze(-1)

        prev_ma = (self._prev_fvals[:-1] * weights).sum(dim=0)
        ma = (self._prev_fvals[1:] * weights).sum(dim=0)
        # rel_delta = (prev_ma - ma) / prev_ma.abs()
        rel_delta = (prev_ma - ma).abs() / prev_ma.abs()  # This was modified compared to the original function

        if not self.minimize:
            rel_delta = -rel_delta
        if torch.max(rel_delta) < self.rel_tol:
            return True

        return False


def fit_gplvm_scipy(
    mll: MarginalLogLikelihood,
    bounds: Optional[ParameterBounds] = None,
    method: str = "L-BFGS-B",
    options: Optional[Dict[str, Any]] = None,
    track_iterations: bool = True,
    approx_mll: bool = False,
    scipy_objective: TScipyObjective = _scipy_objective_and_grad,
    module_to_array_func: TModToArray = module_to_array,
    module_from_array_func: TArrayToMod = set_params_with_array,
) -> Tuple[MarginalLogLikelihood, Dict[str, Union[float, List[OptimizationIteration]]]]:
    r"""Fit a GPLVM model by maximizing MLL with a scipy optimizer.

    This function was adapted from the function botorch.optim.fit.fit_gpytorch_scipy of botorch to optimize Bayesian
    GPLVMs instead of gpytorch GP models.

    The model and likelihood in mll must already be in train mode.
    This method requires that the model has `train_inputs` and `train_targets`.

    Args:
        mll: MarginalLogLikelihood to be maximized.
        bounds: A dictionary mapping parameter names to tuples of lower and upper
            bounds.
        method: Solver type, passed along to scipy.minimize.
        options: Dictionary of solver options, passed along to scipy.minimize.
        track_iterations: Track the function values and wall time for each
            iteration.
        approx_mll: If True, use gpytorch's approximate MLL computation. This is
            disabled by default since the stochasticity is an issue for
            determistic optimizers). Enabling this is only recommended when
            working with large training data sets (n>2000).

    Returns:
        2-element tuple containing
        - MarginalLogLikelihood with parameters optimized in-place.
        - Dictionary with the following key/values:
        "fopt": Best mll value.
        "wall_time": Wall time of fitting.
        "iterations": List of OptimizationIteration objects with information on each
        iteration. If track_iterations is False, will be empty.
        "OptimizeResult": The result returned by `scipy.optim.minimize`.

    Example:
        >>> mll = VariationalELBO(likelihood, gplvm_model, num_data=num_data)
        >>> mll.train()
        >>> fit_gpytorch_scipy(mll)
        >>> mll.eval()
    """
    options = options or {}
    x0, property_dict, bounds = module_to_array_func(
        module=mll, bounds=bounds, exclude=options.pop("exclude", None)
    )
    x0 = x0.astype(np.float64)
    if bounds is not None:
        bounds = Bounds(lb=bounds[0], ub=bounds[1], keep_feasible=True)

    xs = []
    ts = []
    t1 = time.time()

    def store_iteration(xk):
        xs.append(xk.copy())
        ts.append(time.time() - t1)

    cb = store_iteration if track_iterations else None

    with gpt_settings.fast_computations(log_prob=approx_mll):
        res = minimize(
            scipy_objective,
            x0,
            args=(mll, property_dict),
            bounds=bounds,
            method=method,
            jac=True,
            options=options,
            callback=cb,
        )
        iterations = []
        if track_iterations:
            for i, xk in enumerate(xs):
                obj, _ = scipy_objective(x=xk, mll=mll, property_dict=property_dict)
                iterations.append(OptimizationIteration(i, obj, ts[i]))
    # Construct info dict
    info_dict = {
        "fopt": float(res.fun),
        "wall_time": time.time() - t1,
        "iterations": iterations,
        "OptimizeResult": res,
    }
    if not res.success:
        try:
            # Some res.message are bytes
            msg = res.message.decode("ascii")
        except AttributeError:
            # Others are str
            msg = res.message
        warnings.warn(
            f"Fitting failed with the optimizer reporting '{msg}'", # OptimizationWarning
        )
    # Set to optimum
    mll = module_from_array_func(mll, res.x, property_dict)
    return mll, info_dict


def fit_gplvm_torch(
    mll: MarginalLogLikelihood,
    bounds: Optional[ParameterBounds] = None,  # TODO this may be unuseful in our case
    optimizer_cls: Optimizer = Adam,
    options: Optional[Dict[str, Any]] = None,
    track_iterations: bool = True,
    approx_mll: bool = True,
    model_path: str = None,
) -> Tuple[MarginalLogLikelihood, Dict[str, Union[float, List[OptimizationIteration]]]]:
    r"""Fit a GPLVM model by maximizing MLL with a torch optimizer.

    This function was adapted from the function botorch.optim.fit.fit_gpytorch_torch of botorch to optimize Bayesian
    GPLVMs instead of gpytorch GP models.

    The model and likelihood in mll must already be in train mode.
    Note: this method requires that the model has `train_inputs` and `train_targets`.

    Args:
        mll: MarginalLogLikelihood to be maximized.
        bounds: A ParameterBounds dictionary mapping parameter names to tuples
            of lower and upper bounds. Bounds specified here take precedence
            over bounds on the same parameters specified in the constraints
            registered with the module.
        optimizer_cls: Torch optimizer to use. Must not require a closure.
        options: options for model fitting. Relevant options will be passed to
            the `optimizer_cls`. Additionally, options can include: "disp"
            to specify whether to display model fitting diagnostics and "maxiter"
            to specify the maximum number of iterations.
        track_iterations: Track the function values and wall time for each
            iteration.
        approx_mll: If True, use gpytorch's approximate MLL computation (
            according to the gpytorch defaults based on the training at size).
            Unlike for the deterministic algorithms used in fit_gpytorch_scipy,
            this is not an issue for stochastic optimizers.

    Returns:
        2-element tuple containing
        - mll with parameters optimized in-place.
        - Dictionary with the following key/values:
        "fopt": Best mll value.
        "wall_time": Wall time of fitting.
        "iterations": List of OptimizationIteration objects with information on each
        iteration. If track_iterations is False, will be empty.

    Example:
        >>> mll = VariationalELBO(likelihood, gplvm_model, num_data=num_data)
        >>> mll.train()
        >>> fit_gpytorch_torch(mll)
        >>> mll.eval()
    """
    optim_options = {"maxiter": 1000, "disp": True, "lr": 0.05}
    optim_options.update(options or {})
    exclude = optim_options.pop("exclude", None)
    if exclude is not None:
        mll_params = [
            t for p_name, t in mll.named_parameters() if p_name not in exclude
        ]
    else:
        mll_params = list(mll.parameters())

    if optimizer_cls == RiemannianAdam:  # Handles Geoopt optimizer
        optimizer = optimizer_cls(
            params=[{"params": mll_params}],
            **_filter_kwargs(torch.optim.Adam, **optim_options),
        )
    elif optimizer_cls == RiemannianSGD: # Handles Geoopt optimizer
        optimizer = optimizer_cls(
            params=[{"params": mll_params}],
            **_filter_kwargs(torch.optim.SGD, **optim_options),
        )
        # TODO do this cleaner (one way would probably be to init the base class in geoopt optimizers)
    else:
        optimizer = optimizer_cls(
            params=[{"params": mll_params}],
            **_filter_kwargs(optimizer_cls, **optim_options),
        )

    # get bounds specified in model (if any)
    bounds_: ParameterBounds = {}
    if hasattr(mll, "named_parameters_and_constraints"):
        for param_name, _, constraint in mll.named_parameters_and_constraints():
            if constraint is not None and not constraint.enforced:
                bounds_[param_name] = constraint.lower_bound, constraint.upper_bound

    # update with user-supplied bounds (overwrites if already exists)
    if bounds is not None:
        bounds_.update(bounds)

    iterations = []
    t1 = time.time()

    param_trajectory: Dict[str, List[Tensor]] = {
        name: [] for name, param in mll.named_parameters()
    }
    loss_trajectory: List[float] = []
    i = 0
    stop = False
    stopping_criterion = ExpMAStoppingCriterion(
        **_filter_kwargs(ExpMAStoppingCriterion, **optim_options)
    )

    train_targets = mll.model.train_targets
    while not stop:
        if hasattr(mll.model.train_inputs, '__call__'):
            # For variational GPLVMs, the training inputs are sampled at each iteration
            # For back-constrained GPLVMs, the training inputs are computed as a function of the training targets
            train_inputs = mll.model.train_inputs()
        else:
            # For exact GPLVMs, the training inputs are fixed
            train_inputs = mll.model.train_inputs[0]

        optimizer.zero_grad()
        with gpt_settings.fast_computations(log_prob=approx_mll):
            output = mll.model(train_inputs)
            # we sum here to support batch mode
            args = [output, train_targets] + _get_extra_mll_args(mll)
            loss = -mll(*args).sum()
            loss.backward(retain_graph=True)
        loss_trajectory.append(loss.item())
        for name, param in mll.named_parameters():
            param_trajectory[name].append(param.detach().clone())
        if optim_options["disp"] and (
            (i + 1) % 1 == 0 or i == (optim_options["maxiter"] - 1)
        ):
            print(f"Iter {i + 1}/{optim_options['maxiter']}: {loss.item()}")
        if track_iterations:
            iterations.append(OptimizationIteration(i, loss.item(), time.time() - t1))
        # Save the model
        # if model_path and (i + 1) % 20 == 0:
        #     torch.save(mll.state_dict(), model_path)
        # start = time.time()
        optimizer.step()
        # print(time.time() - start)

        # project onto bounds:
        if bounds_:
            for pname, param in mll.named_parameters():
                if pname in bounds_:
                    param.data = param.data.clamp(*bounds_[pname])
        i += 1
        stop = stopping_criterion.evaluate(fvals=loss.detach())
    info_dict = {
        "fopt": loss_trajectory[-1],
        "wall_time": time.time() - t1,
        "iterations": iterations,
    }
    if model_path:
        torch.save(mll.state_dict(), model_path)
    return mll, info_dict


def fit_gplvm_torch_with_logger(
        mll: MarginalLogLikelihood, 
        bounds: Optional[ParameterBounds] = None, 
        optimizer_cls: Optimizer = Adam,
        lr_scheduler: torch.optim.lr_scheduler = None, 
        stop_criterion : StoppingCriterion = VanillaStoppingCriterion,
        options: Optional[Dict[str, Any]] = None, 
        lr_options: Optional[Dict[str, Any]] = None,
        stop_crit_options: Optional[Dict[str, Any]] = None,
        alt_opt_options: Optional[Dict[str, Any]] = None, 
        logger: Logger = None) \
        -> MarginalLogLikelihood:
    r"""
    Fit a GPLVM model by maximizing MLL with a torch optimizer. This function was adapted from the function
    botorch.optim.fit.fit_gpytorch_torch of botorch to optimize Bayesian GPLVMs instead of gpytorch GP models.

    The model and likelihood in the MLL must already be in train mode. Note that this method requires that the model has
    `train_inputs` and `train_targets`.

    Parameters
    ----------
    mll : MarginalLogLikelihood
        the marginal log likelihood to be maximized.
    model : gpytorch.models.ExactGP
        the Riemannian GPLVM model
    manifold : Manifold_VCurvature
        the instantiated manifold that defines the latent space
    bounds : Optional[ParameterBounds]
        a ParameterBounds dictionary mapping parameter names to tuples of lower and upper bounds. Bounds specified here
        take precedence over bounds on the same parameters specified in the constraints registered with the module.
        (default: None)
    optimizer_cls : Optional[Optimizer]
        torch optimizer to use. Must not require a closure. (default: Adam)
    lr_scheduler : Optional[torch.optim.lr_scheduler]
        learning rate scheduler that changes the learning rate depending on the condition. Currently only supports
        ReduceLROnPlateau as scheduler that can be instantiated within the optimisation script. (default: None)
    stop_criterion : Optional[StoppingCriterion]
        stopping criterion to be used. Currently only the vanilla version and the exponential moving average is
        supported. (default: VanillaStoppingCriterion)
    options :  Optional[Dict[str, Any]]
        options for model fitting. Relevant options will be passed to the `optimizer_cls`. Additionally, options can
        include: "disp" to specify whether to display model fitting diagnostics and "maxiter" to specify the maximum
        number of iterations. (default: {"maxiter": 1000, "disp": True, "lr": 0.05})
    lr_options : Optional[Dict[str, Any]]
        options for learning rate scheduler. Relevant options will be passed to the 'lr_scheduler'. Additionally, options
        can include: "mode" to specify if the monitored quantity should decrease or increase, "verbose" to specify if
        information should be printed onto the console if changes to the learning rate is made. (default: {"mode": min,
        "verbose": True})
    stop_crit_options : Optional[Dict[str, Any]]
        options for the stopping criterion. Relevant options will be passed to the 'stop_criterion'. (default: None)
    alt_opt_options : Optional[Dict[str, Any]]
        options for curvature fitting. Relevant options will be passed to the Euclidean optimizer that is used to
        optimize the curvature value of the manifold. Options can include: "lr" to specify the learning rate, "opti_split"
        to specify the split between the Riemannian and Euclidean optimisation. (default: {"lr": 0.001,
        "opti_split": (50,20)}
    logger : Optional[Logger]
        variable to store the logger that logs all relevant information from training. (default: None)

    Returns
    -------
    MarginalLogLikelihood
        MLL with parameters optimized in-place

    Example
    -------
        >>> mll = VariationalELBO(likelihood, gplvm_model, num_data=num_data)
        >>> mll.train()
        >>> fit_gpytorch_torch(mll, model)
        >>> mll.eval()

    Note
    ----
    (1) We differentiate between two optimizers, the Riemannian optimizer (R_optimizer) and the Euclidean optimizer
        (E_optimizer). The former will optimize the common parameters in GPHLVM, i.e. likelihood.noise_covar.raw_noise,
        model.X.X, model.covar_module.raw_outputscale, model.covar_module.base_kernel.raw_lengthscale. The latter will
        optimize exclusively the manifold curvature. Both optimizers will operate in an alternating fashion.     (08.03)

    """
    # Retrieve the parameters for the optimiser(s) and print parameters before training to check
    exclude = options.pop("exclude", None)
    if exclude is not None:
        model_param = [
            t for p_name, t in mll.named_parameters() if p_name not in exclude
        ]
    else:
        model_param = list(mll.parameters())

    # Set default optimisation options and update them if the input 'options' is not None
    optim_options = {"maxiter": 1000, "disp": True, "lr": 0.05}
    optim_options.update(options or {})

    # Set default learning rate scheduler options and update them if the input 'lr_options' is not None
    scheduler_options = {"mode": 'min', "verbose": True}
    scheduler_options.update(lr_options or {})

    # Set default stopping criterion options and update them if the input 'stop_crtierion_options' is not None
    stop_criterion_options = {"maxiter": 1000}
    stop_criterion_options.update(stop_crit_options or {})

    # Initialise the Riemannian optimizer
    if optimizer_cls == RiemannianAdam:
        optimizer = optimizer_cls(params=[{"params": model_param}], **_filter_kwargs(torch.optim.Adam, **optim_options))
    elif optimizer_cls == RiemannianSGD:
        optimizer = optimizer_cls(params=[{"params": model_param}], **_filter_kwargs(torch.optim.SGD, **optim_options))
    else:
        optimizer = optimizer_cls(params=[{"params": model_param}], **_filter_kwargs(optimizer_cls, **optim_options))

    # Initialise scheduler
    if lr_scheduler == ReduceLROnPlateau:
        scheduler = lr_scheduler(optimizer=optimizer, **_filter_kwargs(ReduceLROnPlateau, **scheduler_options))
    elif lr_scheduler is not None:
        scheduler = lr_scheduler(optimizer=optimizer, **_filter_kwargs(lr_scheduler, **scheduler_options))

    # Initialise the stopping criterion
    if stop_criterion == VanillaStoppingCriterion:
        stopping_criterion = VanillaStoppingCriterion(**_filter_kwargs(VanillaStoppingCriterion, **stop_criterion_options))
    elif stop_criterion == ExpMAStoppingCriterion:
        stopping_criterion = ExpMAStoppingCriterion(**_filter_kwargs(ExpMAStoppingCriterion, **stop_criterion_options))
    else:
        stopping_criterion = stop_criterion(**_filter_kwargs(StoppingCriterion, **stop_criterion_options))

    # Get bounds specified for each parameter in model (if any)
    bounds_ = {}                                                          # Initialise an empty dictionary that follows the structure of ParameterBounds
    if hasattr(mll, "named_parameters_and_constraints"):                  # Enter existing model parameter constrains into the bounds_ dictionary
        for param_name, _, constraint in mll.named_parameters_and_constraints():
            if constraint is not None and not constraint.enforced:
                bounds_[param_name] = constraint.lower_bound, constraint.upper_bound
    if bounds is not None:                                                # Update with user-supplied bounds (overwrites if already exists)
        bounds_.update(bounds)

    def compute_loss(train_inputs) -> Tensor:
        # Compute the Gaussian Process prior by giving the training inputs to the Riemannian GPLVM model
        output = mll.model(train_inputs)

        # Compute the loss of the model, which is defined here as the negative of the marginal log likelihood
        train_targets = mll.model.train_targets
        args = [output, train_targets] + _get_extra_mll_args(mll)
        # computed_loss = -mll(*args)
        computed_loss = -mll(*args).sum()
        return computed_loss

    # Initialise training relevant variables
    i = 0
    stop = False

    while not stop:
        # Retrieve training inputs from models
        if hasattr(mll.model.train_inputs, '__call__'):
            # For variational GPLVMs, the training inputs are sampled at each iteration
            # For back-constrained GPLVMs, the training inputs are computed as a function of the training targets
            train_inputs = mll.model.train_inputs()
        else:
            # For exact GPLVMs, the training inputs are fixed
            train_inputs = mll.model.train_inputs[0]

        optimizer.zero_grad()
        loss = compute_loss(train_inputs)

        # Log information onto the logger
        if logger:
            logger.log(step=i, n_steps=optim_options["maxiter"], loss=loss.item(),
                        X=train_inputs.cpu().detach().numpy(), parameters=get_transformed_parameters(mll),
                        state_dict=mll.state_dict(), mll=mll)

        # Print information on current backward pass onto the console
        if optim_options["disp"] and ((i + 1) % 1 == 0 or i == (optim_options["maxiter"] - 1)):
            print(f"Iter {i + 1}/{optim_options['maxiter']}: {loss.item():.5f}")

        # Call the scheduler
        if lr_scheduler is not None:
            scheduler.step(loss.detach())

        i += 1
        # Evaluate the stopping criterion
        if stop_criterion == VanillaStoppingCriterion:
            stop = stopping_criterion.evaluate()
        else:
            stop = stopping_criterion.evaluate(fvals=loss.detach())
        if stop:
            break

        # Compute the backward step w.r.t. the loss and update the optimiser
        loss.backward(retain_graph=False)  # Back propagation

        # Carry out an optimization step
        optimizer.step()  # Gradient descent

        # Project the parameters onto bounds
        if bounds_:
            for pname, param in mll.named_parameters():
                if pname in bounds_:
                    param_old = param.item()
                    param_new = clamp(param, *bounds_[pname])
                    if not math.isclose(param_old, param_new.item()):
                        logging.info(f"The parameter {pname} was clamped from {param_old:.4f} to the specified boundary of {param_new}")
                    param.data = param_new  # Overwrite the parameter value

        del loss

    # Compute final loss after optimisation has been stopped. Save information in logger and info_dict
    if hasattr(mll.model.train_inputs, '__call__'):
        # For variational GPLVMs, the training inputs are sampled at each iteration
        # For back-constrained GPLVMs, the training inputs are computed as a function of the training targets
        train_inputs = mll.model.train_inputs()
    else:
        # For exact GPLVMs, the training inputs are fixed
        train_inputs = mll.model.train_inputs[0]
    final_loss = compute_loss(train_inputs)
    if logger:
        logger.log(step=i, n_steps=optim_options["maxiter"], loss=final_loss.item(),
                   X=train_inputs.cpu().detach().numpy(), parameters=get_transformed_parameters(mll),
                   state_dict=mll.state_dict(), mll=mll)

    return mll
